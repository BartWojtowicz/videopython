[project]
name = "videopython"
version = "0.16.0"
description = "Minimal video generation and processing library."
authors = [
    { name = "Bartosz WÃ³jtowicz", email = "bartoszwojtowicz@outlook.com" },
    { name = "Bartosz Rudnikowicz", email = "bartoszrudnikowicz840@gmail.com" },
    { name = "Piotr Pukisz", email = "piotr.pukisz@gmail.com" },
]
license = { text = "Apache-2.0" }
readme = "README.md"
requires-python = ">=3.10, <3.13"
keywords = [
    "python",
    "videopython",
    "video",
    "movie",
    "opencv",
    "generation",
    "editing",
    "ai",
    "shorts",
]
classifiers = [
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Operating System :: OS Independent",
]

dependencies = [
    "numpy>=1.25.2",
    "opencv-python>=4.9.0.80",
    "pillow>=10.3.0",
    "torchcodec>=0.9.1",
    "tqdm>=4.66.3",
]

[dependency-groups]
dev = [
    "ruff>=0.1.14",
    "mypy>=1.8.0",
    "pytest>=7.4.0",
    "types-Pillow>=10.2.0.20240213",
    "types-tqdm>=4.66.0.20240106",
    "pytest-cov>=6.1.1",
    "mkdocs>=1.6.1",
    "mkdocs-material>=9.7.1",
    "mkdocstrings>=1.0.0",
    "mkdocstrings-python>=2.0.1",
]
ai = [
    "accelerate>=0.29.2",
    "diffusers>=0.26.3",
    "hf-transfer>=0.1.9",
    "torch>=2.1.0",
    "transformers>=4.38.1",
    "openai-whisper>=20240930",
    "whisperx>=3.4.2",
    "numba>=0.61.0",
    "ollama>=0.4.5",
    "scipy>=1.10.0",
    "scikit-learn>=1.3.0",
    # Cloud backend SDKs
    "openai>=1.0.0",
    "google-generativeai>=0.8.0",
    "elevenlabs>=1.0.0",
    "httpx>=0.27.0",
    "runwayml>=0.10.0",
    "lumaai>=1.0.0",
    # Detection backends
    "ultralytics>=8.0.0",
    "easyocr>=1.7.0",
    # Audio classification (AST via transformers - no separate dep needed)
    # Scene detection
    "transnetv2-pytorch>=1.0.5",
    # Voice cloning TTS (coqui-tts is the maintained fork of TTS)
    "coqui-tts>=0.24.0",
    # Audio source separation
    "demucs>=4.0.0",
    # HTTP requests for dubbing API
    "requests>=2.28.0",
    # Cloud backend for object swapping
    "replicate>=0.20.0",
]

# Required for pip install videopython[ai] - pip uses optional-dependencies, not dependency-groups
[project.optional-dependencies]
dev = [
    "ruff>=0.1.14",
    "mypy>=1.8.0",
    "pytest>=7.4.0",
    "types-Pillow>=10.2.0.20240213",
    "types-tqdm>=4.66.0.20240106",
    "pytest-cov>=6.1.1",
]
ai = [
    "accelerate>=0.29.2",
    "diffusers>=0.26.3",
    "hf-transfer>=0.1.9",
    "torch>=2.1.0",
    "transformers>=4.38.1",
    "openai-whisper>=20240930",
    "whisperx>=3.4.2",
    "numba>=0.61.0",
    "ollama>=0.4.5",
    "scipy>=1.10.0",
    "scikit-learn>=1.3.0",
    # Cloud backend SDKs
    "openai>=1.0.0",
    "google-generativeai>=0.8.0",
    "elevenlabs>=1.0.0",
    "httpx>=0.27.0",
    "runwayml>=0.10.0",
    "lumaai>=1.0.0",
    # Detection backends
    "ultralytics>=8.0.0",
    "easyocr>=1.7.0",
    # Audio classification (AST via transformers - no separate dep needed)
    # Scene detection
    "transnetv2-pytorch>=1.0.5",
    # Voice cloning TTS (coqui-tts is the maintained fork of TTS)
    "coqui-tts>=0.24.0",
    # Audio source separation
    "demucs>=4.0.0",
    # HTTP requests for dubbing API
    "requests>=2.28.0",
    # Cloud backend for object swapping
    "replicate>=0.20.0",
]

[project.urls]
Homepage = "https://videopython.com"
Repository = "https://github.com/bartwojtowicz/videopython/"
Documentation = "https://videopython.com"

[tool.mypy]
mypy_path = "src/stubs"

[[tool.mypy.overrides]]
module = [
    "torch", "torch.*",
    "diffusers", "diffusers.*",
    "ollama", "ollama.*",
    "elevenlabs", "elevenlabs.*",
    "google.generativeai", "google.generativeai.*",
    "ultralytics", "ultralytics.*",
    "easyocr", "easyocr.*",
    "transformers", "transformers.*",
    "transnetv2_pytorch", "transnetv2_pytorch.*",
    "TTS", "TTS.*", "coqui", "coqui.*",
    "demucs", "demucs.*",
    "replicate", "replicate.*",
    "cv2", "cv2.*",
]
ignore_missing_imports = true

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/videopython"]

[tool.hatch.build.targets.sdist]
include = ["src/videopython", "src/videopython/py.typed"]

[tool.pytest.ini_options]
pythonpath = ["src/"]
testpaths = ["src/tests"]
python_files = ["test_*.py"]
addopts = ["-v", "--tb=short"]
markers = [
    "requires_model_download: marks tests that require downloading ML models (skipped in CI)",
]

[tool.ruff]
line-length = 120
target-version = "py310"

[tool.ruff.lint]
select = [
    "E", # pycodestyle errors
    "F", # pyflakes
    "I", # isort
    "UP006", # Use PEP 604 annotation (e.g., `list[str]` instead of `typing.List[str]`)
    "UP007", # Use `X | Y` for type annotations (instead of `Optional[X]` and `Union[X, Y]`)
]
isort.known-first-party = ["videopython"]

[tool.ruff.format]
indent-style = "space"
quote-style = "double"
